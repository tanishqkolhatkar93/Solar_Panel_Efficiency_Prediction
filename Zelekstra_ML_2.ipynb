{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1_eZJmQl3KfT"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import pickle\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('train.csv')\n",
        "\n",
        "# View columns with problematic entries\n",
        "print(\"üîç Checking for bad values:\")\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        print(f\"\\nColumn: {col}\")\n",
        "        print(df[col].value_counts())\n",
        "\n",
        "# Replace or drop rows with 'badval' or similar\n",
        "df.replace('badval', np.nan, inplace=True)\n",
        "\n",
        "# Convert all numeric columns to proper types\n",
        "for col in df.columns:\n",
        "    if col not in ['id', 'string_id', 'error_code', 'installation_type']:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_cols = ['string_id', 'error_code', 'installation_type']\n",
        "df[categorical_cols] = df[categorical_cols].astype(str)\n",
        "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Split features and target\n",
        "X = df_encoded.drop(columns=['id', 'efficiency'])\n",
        "y = df_encoded['efficiency']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Scoring function\n",
        "def get_score(y_true, y_pred):\n",
        "    return 100 * (1 - np.sqrt(mean_squared_error(y_true, y_pred)))\n",
        "\n",
        "# Train and compare models\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'GradientBoosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
        "}\n",
        "\n",
        "best_model = None\n",
        "best_score = -np.inf\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    preds = model.predict(X_val_scaled)\n",
        "    score = get_score(y_val, preds)\n",
        "    print(f\"{name} Score: {score:.2f}\")\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_model = model\n",
        "\n",
        "print(\"\\n‚úÖ Best Model:\", best_model.__class__.__name__)\n",
        "print(\"üéØ Best Score:\", round(best_score, 2))\n",
        "\n",
        "# Save the best model\n",
        "with open(\"best_solar_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(best_model, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61D5m0ct6853",
        "outputId": "e8f5ed02-2cdc-47a4-9047-b23ad68b7201"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Checking for bad values:\n",
            "\n",
            "Column: humidity\n",
            "humidity\n",
            "unknown               12\n",
            "error                 10\n",
            "badval                 7\n",
            "5.943344787571525      1\n",
            "65.80376774001192      1\n",
            "                      ..\n",
            "53.27151264182748      1\n",
            "39.44616847963911      1\n",
            "23.871028628631695     1\n",
            "33.254590849551434     1\n",
            "46.07720368087014      1\n",
            "Name: count, Length: 4494, dtype: int64\n",
            "\n",
            "Column: wind_speed\n",
            "wind_speed\n",
            "unknown               9\n",
            "error                 8\n",
            "badval                5\n",
            "3.5726456615192026    1\n",
            "2.3842914378686486    1\n",
            "                     ..\n",
            "8.061014922753328     1\n",
            "3.9543370599359577    1\n",
            "10.701360275854071    1\n",
            "4.481020398384388     1\n",
            "7.137585549949118     1\n",
            "Name: count, Length: 4501, dtype: int64\n",
            "\n",
            "Column: pressure\n",
            "pressure\n",
            "unknown               13\n",
            "error                 10\n",
            "badval                 9\n",
            "1001.5575671939629     1\n",
            "1012.3993993872118     1\n",
            "                      ..\n",
            "1019.2609543313911     1\n",
            "1000.5589830071985     1\n",
            "1011.1038770353858     1\n",
            "1005.4653107849828     1\n",
            "1021.2039421479581     1\n",
            "Name: count, Length: 4491, dtype: int64\n",
            "\n",
            "Column: string_id\n",
            "string_id\n",
            "B2    1151\n",
            "D4    1129\n",
            "C3    1127\n",
            "A1    1113\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: error_code\n",
            "error_code\n",
            "E00    1357\n",
            "E01     965\n",
            "E02     882\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Column: installation_type\n",
            "installation_type\n",
            "fixed        1131\n",
            "dual-axis    1126\n",
            "tracking     1123\n",
            "Name: count, dtype: int64\n",
            "LinearRegression Score: 89.37\n",
            "RandomForest Score: 88.78\n",
            "GradientBoosting Score: 89.11\n",
            "XGBoost Score: 88.33\n",
            "\n",
            "‚úÖ Best Model: LinearRegression\n",
            "üéØ Best Score: 89.37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (previous code)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Save the scaler\n",
        "with open(\"scaler.pkl\", \"wb\") as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "# ... (rest of your code for model training and saving)"
      ],
      "metadata": {
        "id": "1tQkuedIE0i7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training your model and encoding your data\n",
        "required_columns = X_train.columns.tolist()\n",
        "\n",
        "# Save it\n",
        "import pickle\n",
        "with open(\"columns.pkl\", \"wb\") as f:\n",
        "    pickle.dump(required_columns, f)\n"
      ],
      "metadata": {
        "id": "jwvTN0um69cT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wiYUZBa9zZAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "5ZSpr4EUuzQ-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_EutPpfezbm7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}